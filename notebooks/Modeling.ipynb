{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d2da6c1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b739803a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import orjson \n",
    "import pandas as pd \n",
    "import polars as pl\n",
    "from time import sleep\n",
    "\n",
    "# x = requests.get('https://api.opendota.com/api/publicMatches', params={'less_than_match_id':7075980402})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a91401a6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# df = pl.read_parquet('../DATA/tmp_03.20.2023.10.08.35.parquet').to_pandas()\n",
    "# SET = set()\n",
    "# for idx, row in tqdm(df.iterrows()):\n",
    "#     SET.update(row['winner_team'])\n",
    "    \n",
    "# TRANSFORM = {hero_id : idx + 1 for idx, hero_id in enumerate(list(SET))}\n",
    "# TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a734373b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pl.read_parquet('DATA/tmp_01.09.2025.15.23.46.parquet')  # tmp_03.11.2023.03.58.04.parquet\n",
    "df = df.to_pandas()\n",
    "df['avg_rank_tier'] = df['avg_rank_tier'].apply(lambda x: min(5, x // 10 - 1))\n",
    "df = pl.from_pandas(df).with_columns(\n",
    "    pl.when(\"radiant_win\").then(\"radiant_team\").otherwise(\"dire_team\").alias(\"winner_team\"),\n",
    "    pl.when(\"radiant_win\").then(\"dire_team\").otherwise(\"radiant_team\").alias(\"loser_team\")\n",
    ").drop(['dire_team', 'radiant_team', 'radiant_win'])\n",
    "DICTS = df.to_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a49931ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2_611_223, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>match_id</th><th>match_seq_num</th><th>duration</th><th>start_time</th><th>game_mode</th><th>avg_rank_tier</th><th>winner_team</th><th>loser_team</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>list[i64]</td><td>list[i64]</td></tr></thead><tbody><tr><td>8121174818</td><td>6828143444</td><td>2493</td><td>1736436226</td><td>22</td><td>5</td><td>[41, 25, … 2]</td><td>[138, 96, … 84]</td></tr><tr><td>8121174816</td><td>6828139657</td><td>2195</td><td>1736436226</td><td>22</td><td>5</td><td>[84, 54, … 29]</td><td>[8, 36, … 96]</td></tr><tr><td>8121174713</td><td>6828125565</td><td>1496</td><td>1736436226</td><td>22</td><td>1</td><td>[49, 31, … 4]</td><td>[46, 16, … 5]</td></tr><tr><td>8121174711</td><td>6828125144</td><td>1656</td><td>1736436226</td><td>4</td><td>1</td><td>[136, 86, … 68]</td><td>[82, 44, … 123]</td></tr><tr><td>8121174901</td><td>6828124639</td><td>1586</td><td>1736436226</td><td>22</td><td>3</td><td>[62, 96, … 54]</td><td>[67, 99, … 119]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>8165073615</td><td>6863453759</td><td>1305</td><td>1739027192</td><td>22</td><td>3</td><td>[74, 8, … 3]</td><td>[35, 69, … 73]</td></tr><tr><td>8165073801</td><td>6863451148</td><td>1205</td><td>1739027198</td><td>22</td><td>5</td><td>[138, 44, … 62]</td><td>[70, 85, … 17]</td></tr><tr><td>8165074101</td><td>6863455030</td><td>1325</td><td>1739027207</td><td>22</td><td>4</td><td>[8, 88, … 112]</td><td>[4, 2, … 20]</td></tr><tr><td>8165074209</td><td>6863448400</td><td>1052</td><td>1739027212</td><td>22</td><td>4</td><td>[91, 145, … 29]</td><td>[26, 13, … 1]</td></tr><tr><td>8165085305</td><td>6863454163</td><td>948</td><td>1739027573</td><td>22</td><td>2</td><td>[60, 48, … 68]</td><td>[76, 36, … 21]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2_611_223, 8)\n",
       "┌────────────┬────────────┬──────────┬────────────┬───────────┬────────────┬───────────┬───────────┐\n",
       "│ match_id   ┆ match_seq_ ┆ duration ┆ start_time ┆ game_mode ┆ avg_rank_t ┆ winner_te ┆ loser_tea │\n",
       "│ ---        ┆ num        ┆ ---      ┆ ---        ┆ ---       ┆ ier        ┆ am        ┆ m         │\n",
       "│ i64        ┆ ---        ┆ i64      ┆ i64        ┆ i64       ┆ ---        ┆ ---       ┆ ---       │\n",
       "│            ┆ i64        ┆          ┆            ┆           ┆ i64        ┆ list[i64] ┆ list[i64] │\n",
       "╞════════════╪════════════╪══════════╪════════════╪═══════════╪════════════╪═══════════╪═══════════╡\n",
       "│ 8121174818 ┆ 6828143444 ┆ 2493     ┆ 1736436226 ┆ 22        ┆ 5          ┆ [41, 25,  ┆ [138, 96, │\n",
       "│            ┆            ┆          ┆            ┆           ┆            ┆ … 2]      ┆ … 84]     │\n",
       "│ 8121174816 ┆ 6828139657 ┆ 2195     ┆ 1736436226 ┆ 22        ┆ 5          ┆ [84, 54,  ┆ [8, 36, … │\n",
       "│            ┆            ┆          ┆            ┆           ┆            ┆ … 29]     ┆ 96]       │\n",
       "│ 8121174713 ┆ 6828125565 ┆ 1496     ┆ 1736436226 ┆ 22        ┆ 1          ┆ [49, 31,  ┆ [46, 16,  │\n",
       "│            ┆            ┆          ┆            ┆           ┆            ┆ … 4]      ┆ … 5]      │\n",
       "│ 8121174711 ┆ 6828125144 ┆ 1656     ┆ 1736436226 ┆ 4         ┆ 1          ┆ [136, 86, ┆ [82, 44,  │\n",
       "│            ┆            ┆          ┆            ┆           ┆            ┆ … 68]     ┆ … 123]    │\n",
       "│ 8121174901 ┆ 6828124639 ┆ 1586     ┆ 1736436226 ┆ 22        ┆ 3          ┆ [62, 96,  ┆ [67, 99,  │\n",
       "│            ┆            ┆          ┆            ┆           ┆            ┆ … 54]     ┆ … 119]    │\n",
       "│ …          ┆ …          ┆ …        ┆ …          ┆ …         ┆ …          ┆ …         ┆ …         │\n",
       "│ 8165073615 ┆ 6863453759 ┆ 1305     ┆ 1739027192 ┆ 22        ┆ 3          ┆ [74, 8, … ┆ [35, 69,  │\n",
       "│            ┆            ┆          ┆            ┆           ┆            ┆ 3]        ┆ … 73]     │\n",
       "│ 8165073801 ┆ 6863451148 ┆ 1205     ┆ 1739027198 ┆ 22        ┆ 5          ┆ [138, 44, ┆ [70, 85,  │\n",
       "│            ┆            ┆          ┆            ┆           ┆            ┆ … 62]     ┆ … 17]     │\n",
       "│ 8165074101 ┆ 6863455030 ┆ 1325     ┆ 1739027207 ┆ 22        ┆ 4          ┆ [8, 88, … ┆ [4, 2, …  │\n",
       "│            ┆            ┆          ┆            ┆           ┆            ┆ 112]      ┆ 20]       │\n",
       "│ 8165074209 ┆ 6863448400 ┆ 1052     ┆ 1739027212 ┆ 22        ┆ 4          ┆ [91, 145, ┆ [26, 13,  │\n",
       "│            ┆            ┆          ┆            ┆           ┆            ┆ … 29]     ┆ … 1]      │\n",
       "│ 8165085305 ┆ 6863454163 ┆ 948      ┆ 1739027573 ┆ 22        ┆ 2          ┆ [60, 48,  ┆ [76, 36,  │\n",
       "│            ┆            ┆          ┆            ┆           ┆            ┆ … 68]     ┆ … 21]     │\n",
       "└────────────┴────────────┴──────────┴────────────┴───────────┴────────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df  #  (2433383, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f18645a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (7, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>game_mode</th><th>count</th></tr><tr><td>i64</td><td>u32</td></tr></thead><tbody><tr><td>1</td><td>18</td></tr><tr><td>2</td><td>5231</td></tr><tr><td>4</td><td>63035</td></tr><tr><td>22</td><td>2516163</td></tr><tr><td>16</td><td>40</td></tr><tr><td>5</td><td>1</td></tr><tr><td>3</td><td>26735</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (7, 2)\n",
       "┌───────────┬─────────┐\n",
       "│ game_mode ┆ count   │\n",
       "│ ---       ┆ ---     │\n",
       "│ i64       ┆ u32     │\n",
       "╞═══════════╪═════════╡\n",
       "│ 1         ┆ 18      │\n",
       "│ 2         ┆ 5231    │\n",
       "│ 4         ┆ 63035   │\n",
       "│ 22        ┆ 2516163 │\n",
       "│ 16        ┆ 40      │\n",
       "│ 5         ┆ 1       │\n",
       "│ 3         ┆ 26735   │\n",
       "└───────────┴─────────┘"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['game_mode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c85ed82c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2350100, 261123)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_DICTS = DICTS[-len(DICTS) // 10:]\n",
    "TRAIN_DICTS = DICTS[:-len(DICTS) // 10]\n",
    "len(TRAIN_DICTS), len(TEST_DICTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8e4df54",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from picker.model.dataset import TeamDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93446d2d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# df = pl.read_parquet('../DATA/tmp_03.20.2023.10.08.35.parquet').to_pandas()\n",
    "# SET = set()\n",
    "# for idx, row in tqdm(df.iterrows()):\n",
    "#     SET.update(row['winner_team'])\n",
    "    \n",
    "# TRANSFORM = {hero_id : idx + 1 for idx, hero_id in enumerate(list(SET))}\n",
    "# TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57c64188",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data = TeamDataset('', dicts_override=TRAIN_DICTS, p=0.2)\n",
    "test_data1 = TeamDataset('', dicts_override=TEST_DICTS, p=0.0)\n",
    "test_data2 = TeamDataset('', dicts_override=TEST_DICTS, p=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "966ac411",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from picker.model.training_model import run_training\n",
    "from picker.model.transformer import TransformerModel\n",
    "from picker.model.constants import HERO_TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0a72f7c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# embedding_dict = {'team': [len(HERO_TRANSFORM) + 1, 15], 'enemy': [len(HERO_TRANSFORM) + 1, 32]} \n",
    "embedding_dict = {'team': [len(HERO_TRANSFORM) + 1, 32 - 3 - 1], 'rank': [6, 3]} \n",
    "model = TransformerModel(embedding_dict=embedding_dict, num_heads=8, num_layers=6,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1dd3082b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train...:   2%|█▌                                                                                                | 9/574 [00:02<02:51,  3.29it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BCELoss, CrossEntropyLoss\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrans-32-0.2-v2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_datas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtest_data1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m             \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3e-4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m             \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m             \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/d/Git_shit_2/shad_courses/picker/picker/model/training_model.py:100\u001b[0m, in \u001b[0;36mrun_training\u001b[0;34m(model, name, train_data, test_datas, criterion, optimizer, epochs, batch_size, device)\u001b[0m\n\u001b[1;32m     97\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m    101\u001b[0m         loss_log \u001b[38;5;241m=\u001b[39m train(\n\u001b[1;32m    102\u001b[0m             model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    103\u001b[0m             train_dl\u001b[38;5;241m=\u001b[39mtrain_dl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m             device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m    107\u001b[0m         )\n\u001b[1;32m    108\u001b[0m         epoch_losses\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(loss_log))\n",
      "File \u001b[0;32m/mnt/d/Git_shit_2/shad_courses/picker/picker/model/training_model.py:29\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dl, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     26\u001b[0m     loss_log\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     28\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 29\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss_log\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/picker-aqmUO_25-py3.10/lib/python3.10/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/picker-aqmUO_25-py3.10/lib/python3.10/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/picker-aqmUO_25-py3.10/lib/python3.10/site-packages/torch/optim/adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 234\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m         \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/picker-aqmUO_25-py3.10/lib/python3.10/site-packages/torch/optim/adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 300\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/picker-aqmUO_25-py3.10/lib/python3.10/site-packages/torch/optim/adam.py:353\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# update step\u001b[39;00m\n\u001b[1;32m    351\u001b[0m step_t \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight_decay \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    354\u001b[0m     grad \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39madd(param, alpha\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(param):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.nn import BCELoss, CrossEntropyLoss\n",
    "import torch\n",
    "\n",
    "run_training(model=model, name='trans-32-0.2-v2', train_data=train_data, test_datas=[test_data1, test_data2],\n",
    "             optimizer=torch.optim.Adam(model.parameters(), lr=3e-4),\n",
    "             criterion=CrossEntropyLoss(),\n",
    "             epochs=100, batch_size=1024 * 8, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "591e8775-86d6-4b1e-a767-89e635c64118",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"zhopa.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3e001ef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/qc7/.cache/pypoetry/virtualenvs/picker-aqmUO_25-py3.10/lib/python3.10/site-packages/torch/_utils.py\u001b[0m(543)\u001b[0;36mreraise\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    541 \u001b[0;31m            \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    542 \u001b[0;31m            \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 543 \u001b[0;31m        \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    544 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    545 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/qc7/.cache/pypoetry/virtualenvs/picker-aqmUO_25-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\u001b[0m(1359)\u001b[0;36m_process_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1357 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1358 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1359 \u001b[0;31m            \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1360 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1361 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/qc7/.cache/pypoetry/virtualenvs/picker-aqmUO_25-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\u001b[0m(1333)\u001b[0;36m_next_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1331 \u001b[0;31m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1332 \u001b[0;31m                \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1333 \u001b[0;31m                \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1334 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1335 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/qc7/.cache/pypoetry/virtualenvs/picker-aqmUO_25-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\u001b[0m(628)\u001b[0;36m__next__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    626 \u001b[0;31m                \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    627 \u001b[0;31m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 628 \u001b[0;31m            \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    629 \u001b[0;31m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    630 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/qc7/.cache/pypoetry/virtualenvs/picker-aqmUO_25-py3.10/lib/python3.10/site-packages/tqdm/std.py\u001b[0m(1195)\u001b[0;36m__iter__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1193 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1194 \u001b[0;31m        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1195 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1196 \u001b[0;31m                \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1197 \u001b[0;31m                \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/mnt/d/Git_shit_2/shad_courses/picker/picker/model/training_model.py\u001b[0m(14)\u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     12 \u001b[0;31m    \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     13 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 14 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Train...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     15 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m            \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/mnt/d/Git_shit_2/shad_courses/picker/picker/model/training_model.py\u001b[0m(100)\u001b[0;36mrun_training\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     98 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     99 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 100 \u001b[0;31m        loss_log = train(\n",
      "\u001b[0m\u001b[0;32m    101 \u001b[0;31m            \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    102 \u001b[0;31m            \u001b[0mtrain_dl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_56155/687358011.py\u001b[0m(4)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      2 \u001b[0;31m\u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      3 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 4 \u001b[0;31mrun_training(model=model, name='trans-32-0.2-v2', train_data=train_data, test_datas=[test_data1, test_data2],\n",
      "\u001b[0m\u001b[0;32m      5 \u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      6 \u001b[0;31m             \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/mnt/d/Git_shit_2/shad_courses/picker/picker/model/training_model.py\u001b[0m(100)\u001b[0;36mrun_training\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     98 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     99 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 100 \u001b[0;31m        loss_log = train(\n",
      "\u001b[0m\u001b[0;32m    101 \u001b[0;31m            \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    102 \u001b[0;31m            \u001b[0mtrain_dl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/mnt/d/Git_shit_2/shad_courses/picker/picker/model/training_model.py\u001b[0m(14)\u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     12 \u001b[0;31m    \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     13 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 14 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Train...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     15 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m            \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/qc7/.cache/pypoetry/virtualenvs/picker-aqmUO_25-py3.10/lib/python3.10/site-packages/tqdm/std.py\u001b[0m(1195)\u001b[0;36m__iter__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1193 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1194 \u001b[0;31m        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1195 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1196 \u001b[0;31m                \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1197 \u001b[0;31m                \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/qc7/.cache/pypoetry/virtualenvs/picker-aqmUO_25-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\u001b[0m(628)\u001b[0;36m__next__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    626 \u001b[0;31m                \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    627 \u001b[0;31m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 628 \u001b[0;31m            \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    629 \u001b[0;31m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    630 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/qc7/.cache/pypoetry/virtualenvs/picker-aqmUO_25-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\u001b[0m(1333)\u001b[0;36m_next_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1331 \u001b[0;31m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1332 \u001b[0;31m                \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1333 \u001b[0;31m                \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1334 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1335 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/qc7/.cache/pypoetry/virtualenvs/picker-aqmUO_25-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py\u001b[0m(1359)\u001b[0;36m_process_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1357 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1358 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1359 \u001b[0;31m            \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1360 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1361 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  exit\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0278f35c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa9e64eb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "from picker.model.transformer import TransformerModel\n",
    "from picker.model.constants import HERO_TRANSFORM\n",
    "\n",
    "embedding_dict = {'team': [len(HERO_TRANSFORM) + 1, 32 - 3 - 1], 'rank': [6, 3]} \n",
    "model = TransformerModel(embedding_dict=embedding_dict, num_heads=8, num_layers=6,)\n",
    "model.load_state_dict(torch.load('zhopa.pth'))\n",
    "\n",
    "model.to('cpu')\n",
    "model.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e5d2188",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# script = torch.jit.script(model)\n",
    "torch.save(model, 'zhopa.raw_model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5a7f672",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5012, 0.4988]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5012, 0.4988]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5012, 0.4988]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5294, 0.4706]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5294, 0.4706]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4673, 0.5327]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5072, 0.4928]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5072, 0.4928]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4926, 0.5074]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4799, 0.5201]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4799, 0.5201]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5170, 0.4830]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4476, 0.5524]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4476, 0.5524]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5609, 0.4391]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5182, 0.4818]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5182, 0.4818]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4797, 0.5203]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4948, 0.5052]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4948, 0.5052]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5039, 0.4961]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5100, 0.4900]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5100, 0.4900]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4978, 0.5022]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4946, 0.5054]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4946, 0.5054]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5017, 0.4983]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5649, 0.4351]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5649, 0.4351]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4387, 0.5613]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5126, 0.4874]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5126, 0.4874]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4826, 0.5174]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5551, 0.4449]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5551, 0.4449]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4422, 0.5578]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5458, 0.4542]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5458, 0.4542]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4511, 0.5489]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5053, 0.4947]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5053, 0.4947]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4950, 0.5050]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5130, 0.4870]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5130, 0.4870]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4948, 0.5052]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4937, 0.5063]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4937, 0.5063]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5144, 0.4856]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5193, 0.4807]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5193, 0.4807]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4883, 0.5117]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4913, 0.5087]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4913, 0.5087]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5048, 0.4952]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5612, 0.4388]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5612, 0.4388]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4486, 0.5514]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5220, 0.4780]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5220, 0.4780]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4771, 0.5229]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4843, 0.5157]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4843, 0.5157]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5187, 0.4813]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5902, 0.4098]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5902, 0.4098]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4209, 0.5791]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4836, 0.5164]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4836, 0.5164]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5193, 0.4807]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5089, 0.4911]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5089, 0.4911]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4858, 0.5142]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4897, 0.5103]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4897, 0.5103]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5134, 0.4866]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5086, 0.4914]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5086, 0.4914]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4932, 0.5068]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4708, 0.5292]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4708, 0.5292]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5293, 0.4707]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5121, 0.4879]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5121, 0.4879]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4945, 0.5055]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4707, 0.5293]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4707, 0.5293]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5204, 0.4796]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5081, 0.4919]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5081, 0.4919]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4921, 0.5079]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4581, 0.5419]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4581, 0.5419]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5452, 0.4548]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4999, 0.5001]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4999, 0.5001]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5093, 0.4907]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4791, 0.5209]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4791, 0.5209]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5241, 0.4759]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4977, 0.5023]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4977, 0.5023]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5067, 0.4933]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5250, 0.4750]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5250, 0.4750]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4752, 0.5248]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5217, 0.4783]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5217, 0.4783]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4867, 0.5133]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5024, 0.4976]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5024, 0.4976]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5032, 0.4968]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5270, 0.4730]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5270, 0.4730]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4855, 0.5145]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5159, 0.4841]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5159, 0.4841]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4940, 0.5060]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5161, 0.4839]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5161, 0.4839]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4875, 0.5125]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5462, 0.4538]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5462, 0.4538]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4561, 0.5439]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4812, 0.5188]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4812, 0.5188]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5200, 0.4800]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5024, 0.4976]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5024, 0.4976]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4951, 0.5049]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5219, 0.4781]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5219, 0.4781]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4880, 0.5120]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5093, 0.4907]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5093, 0.4907]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4942, 0.5058]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5478, 0.4522]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5478, 0.4522]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4464, 0.5536]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5180, 0.4820]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5180, 0.4820]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4711, 0.5289]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5841, 0.4159]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5841, 0.4159]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4168, 0.5832]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5363, 0.4637]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5363, 0.4637]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4663, 0.5337]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5211, 0.4789]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5211, 0.4789]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4781, 0.5219]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4737, 0.5263]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4737, 0.5263]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5303, 0.4697]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5015, 0.4985]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5015, 0.4985]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5040, 0.4960]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5475, 0.4525]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5475, 0.4525]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4518, 0.5482]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4762, 0.5238]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4762, 0.5238]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5235, 0.4765]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5074, 0.4926]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5074, 0.4926]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4965, 0.5035]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4962, 0.5038]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4962, 0.5038]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4965, 0.5035]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4992, 0.5008]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4992, 0.5008]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5006, 0.4994]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5531, 0.4469]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5531, 0.4469]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4663, 0.5337]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5161, 0.4839]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5161, 0.4839]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4852, 0.5148]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4456, 0.5544]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4456, 0.5544]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5516, 0.4484]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4746, 0.5254]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4746, 0.5254]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5313, 0.4687]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4667, 0.5333]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4667, 0.5333]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5322, 0.4678]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5099, 0.4901]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5099, 0.4901]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4905, 0.5095]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5246, 0.4754]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5246, 0.4754]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4767, 0.5233]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5660, 0.4340]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5660, 0.4340]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4327, 0.5673]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5365, 0.4635]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5365, 0.4635]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4592, 0.5408]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4854, 0.5146]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4854, 0.5146]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5134, 0.4866]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4970, 0.5030]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4970, 0.5030]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5149, 0.4851]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5282, 0.4718]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5282, 0.4718]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4836, 0.5164]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4859, 0.5141]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4859, 0.5141]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5121, 0.4879]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4991, 0.5009]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4991, 0.5009]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5032, 0.4968]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5189, 0.4811]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5189, 0.4811]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4841, 0.5159]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4995, 0.5005]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4995, 0.5005]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5063, 0.4937]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5091, 0.4909]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5091, 0.4909]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4965, 0.5035]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4797, 0.5203]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4797, 0.5203]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5263, 0.4737]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4820, 0.5180]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4820, 0.5180]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5197, 0.4803]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5024, 0.4976]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5024, 0.4976]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5019, 0.4981]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5018, 0.4982]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5018, 0.4982]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5020, 0.4980]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4981, 0.5019]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4981, 0.5019]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5043, 0.4957]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4687, 0.5313]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4687, 0.5313]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5212, 0.4788]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5176, 0.4824]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5176, 0.4824]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4853, 0.5147]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5220, 0.4780]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5220, 0.4780]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4910, 0.5090]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5211, 0.4789]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5211, 0.4789]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4853, 0.5147]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4914, 0.5086]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4914, 0.5086]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5161, 0.4839]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4988, 0.5012]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4988, 0.5012]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5132, 0.4868]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5357, 0.4643]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5357, 0.4643]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4705, 0.5295]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4940, 0.5060]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4940, 0.5060]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5051, 0.4949]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4995, 0.5005]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4995, 0.5005]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5006, 0.4994]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5620, 0.4380]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5620, 0.4380]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4319, 0.5681]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5116, 0.4884]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5116, 0.4884]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4912, 0.5088]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5113, 0.4887]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5113, 0.4887]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5019, 0.4981]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4731, 0.5269]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4731, 0.5269]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5360, 0.4640]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5255, 0.4745]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5255, 0.4745]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4771, 0.5229]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4945, 0.5055]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4945, 0.5055]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5225, 0.4775]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5308, 0.4692]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5308, 0.4692]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4797, 0.5203]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5014, 0.4986]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5014, 0.4986]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5046, 0.4954]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5038, 0.4962]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5038, 0.4962]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4994, 0.5006]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5332, 0.4668]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5332, 0.4668]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4722, 0.5278]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5105, 0.4895]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5105, 0.4895]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4907, 0.5093]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5310, 0.4690]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5310, 0.4690]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4760, 0.5240]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5052, 0.4948]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5052, 0.4948]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4918, 0.5082]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4496, 0.5504]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4496, 0.5504]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5624, 0.4376]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4726, 0.5274]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4726, 0.5274]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5375, 0.4625]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4822, 0.5178]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4822, 0.5178]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5226, 0.4774]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5639, 0.4361]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5639, 0.4361]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4339, 0.5661]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5069, 0.4931]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5069, 0.4931]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4996, 0.5004]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4996, 0.5004]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4996, 0.5004]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5062, 0.4938]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4989, 0.5011]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4989, 0.5011]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5093, 0.4907]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5272, 0.4728]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5272, 0.4728]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4763, 0.5237]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5024, 0.4976]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5024, 0.4976]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5044, 0.4956]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4576, 0.5424]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4576, 0.5424]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5473, 0.4527]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4833, 0.5167]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4833, 0.5167]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5142, 0.4858]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4877, 0.5123]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4877, 0.5123]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5157, 0.4843]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5476, 0.4524]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5476, 0.4524]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4627, 0.5373]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5091, 0.4909]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5091, 0.4909]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4927, 0.5073]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5290, 0.4710]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5290, 0.4710]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4732, 0.5268]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5224, 0.4776]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5224, 0.4776]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4735, 0.5265]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5542, 0.4458]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5542, 0.4458]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4546, 0.5454]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4828, 0.5172]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4828, 0.5172]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5179, 0.4821]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5510, 0.4490]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5510, 0.4490]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4547, 0.5453]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5342, 0.4658]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5342, 0.4658]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4677, 0.5323]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4793, 0.5207]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4793, 0.5207]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5223, 0.4777]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4940, 0.5060]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4940, 0.5060]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4968, 0.5032]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5317, 0.4683]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5317, 0.4683]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4601, 0.5399]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5337, 0.4663]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5337, 0.4663]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4641, 0.5359]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5181, 0.4819]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5181, 0.4819]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4839, 0.5161]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4840, 0.5160]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4840, 0.5160]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5187, 0.4813]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "CPU times: user 11.9 s, sys: 3.92 ms, total: 11.9 s\n",
      "Wall time: 1.04 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5011, 0.4989]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5011, 0.4989]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5015, 0.4985]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5148, 0.4852]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5148, 0.4852]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4902, 0.5098]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4968, 0.5032]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4968, 0.5032]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5176, 0.4824]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5412, 0.4588]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5412, 0.4588]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4636, 0.5364]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5042, 0.4958]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5042, 0.4958]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5033, 0.4967]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4812, 0.5188]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4812, 0.5188]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5208, 0.4792]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5203, 0.4797]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5203, 0.4797]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4777, 0.5223]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5244, 0.4756]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5244, 0.4756]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4821, 0.5179]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4892, 0.5108]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4892, 0.5108]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5066, 0.4934]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5182, 0.4818]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5182, 0.4818]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4925, 0.5075]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4994, 0.5006]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4994, 0.5006]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5039, 0.4961]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5468, 0.4532]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5468, 0.4532]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4546, 0.5454]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4755, 0.5245]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4755, 0.5245]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5316, 0.4684]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5076, 0.4924]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5076, 0.4924]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4985, 0.5015]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5225, 0.4775]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5225, 0.4775]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4840, 0.5160]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5585, 0.4415]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5585, 0.4415]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4517, 0.5483]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5123, 0.4877]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5123, 0.4877]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4909, 0.5091]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4900, 0.5100]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4900, 0.5100]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5205, 0.4795]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4557, 0.5443]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4557, 0.5443]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5472, 0.4528]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4403, 0.5597]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4403, 0.5597]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5636, 0.4364]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5467, 0.4533]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5467, 0.4533]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4604, 0.5396]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4775, 0.5225]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4775, 0.5225]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5352, 0.4648]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4907, 0.5093]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4907, 0.5093]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5111, 0.4889]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4752, 0.5248]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4752, 0.5248]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5246, 0.4754]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4673, 0.5327]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4673, 0.5327]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5306, 0.4694]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4991, 0.5009]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4991, 0.5009]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5042, 0.4958]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4836, 0.5164]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4836, 0.5164]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5257, 0.4743]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5252, 0.4748]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5252, 0.4748]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4835, 0.5165]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4834, 0.5166]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4834, 0.5166]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5238, 0.4762]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4851, 0.5149]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4851, 0.5149]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5156, 0.4844]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4949, 0.5051]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4949, 0.5051]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4954, 0.5046]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5009, 0.4991]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5009, 0.4991]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5011, 0.4989]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4815, 0.5185]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4815, 0.5185]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5283, 0.4717]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5208, 0.4792]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5208, 0.4792]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4834, 0.5166]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4934, 0.5066]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4934, 0.5066]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5061, 0.4939]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5071, 0.4929]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5071, 0.4929]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5045, 0.4955]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5261, 0.4739]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5261, 0.4739]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4767, 0.5233]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4673, 0.5327]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4673, 0.5327]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5338, 0.4662]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4906, 0.5094]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4906, 0.5094]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5153, 0.4847]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4326, 0.5674]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4326, 0.5674]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5734, 0.4266]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4774, 0.5226]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4774, 0.5226]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5258, 0.4742]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5230, 0.4770]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5230, 0.4770]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4765, 0.5235]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4455, 0.5545]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4455, 0.5545]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5640, 0.4360]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5064, 0.4936]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5064, 0.4936]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4899, 0.5101]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4445, 0.5555]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4445, 0.5555]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5659, 0.4341]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4925, 0.5075]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4925, 0.5075]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5183, 0.4817]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5112, 0.4888]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5112, 0.4888]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4905, 0.5095]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4813, 0.5187]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4813, 0.5187]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5255, 0.4745]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5253, 0.4747]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5253, 0.4747]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4772, 0.5228]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5046, 0.4954]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5046, 0.4954]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4973, 0.5027]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5050, 0.4950]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5050, 0.4950]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5042, 0.4958]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4844, 0.5156]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4844, 0.5156]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5212, 0.4788]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5188, 0.4812]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5188, 0.4812]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4871, 0.5129]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4845, 0.5155]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4845, 0.5155]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5268, 0.4732]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4283, 0.5717]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4283, 0.5717]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5747, 0.4253]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5008, 0.4992]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5008, 0.4992]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5024, 0.4976]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5251, 0.4749]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5251, 0.4749]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4800, 0.5200]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5232, 0.4768]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5232, 0.4768]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4925, 0.5075]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4900, 0.5100]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4900, 0.5100]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5187, 0.4813]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4962, 0.5038]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4962, 0.5038]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5090, 0.4910]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5431, 0.4569]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5431, 0.4569]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4626, 0.5374]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5528, 0.4472]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5528, 0.4472]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4534, 0.5466]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5171, 0.4829]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5171, 0.4829]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4877, 0.5123]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4966, 0.5034]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4966, 0.5034]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5013, 0.4987]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4964, 0.5036]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4964, 0.5036]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5103, 0.4897]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5006, 0.4994]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5006, 0.4994]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5008, 0.4992]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4713, 0.5287]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4713, 0.5287]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5272, 0.4728]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5052, 0.4948]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5052, 0.4948]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4970, 0.5030]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5106, 0.4894]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5106, 0.4894]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4958, 0.5042]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5104, 0.4896]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5104, 0.4896]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4913, 0.5087]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5053, 0.4947]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5053, 0.4947]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5101, 0.4899]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5151, 0.4849]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5151, 0.4849]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4881, 0.5119]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5048, 0.4952]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5048, 0.4952]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5007, 0.4993]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4828, 0.5172]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4828, 0.5172]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5183, 0.4817]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5081, 0.4919]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5081, 0.4919]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4977, 0.5023]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4681, 0.5319]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4681, 0.5319]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5322, 0.4678]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5110, 0.4890]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5110, 0.4890]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4909, 0.5091]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4966, 0.5034]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4966, 0.5034]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5114, 0.4886]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5106, 0.4894]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5106, 0.4894]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4954, 0.5046]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5438, 0.4562]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5438, 0.4562]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4598, 0.5402]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5235, 0.4765]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5235, 0.4765]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4792, 0.5208]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4948, 0.5052]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4948, 0.5052]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5028, 0.4972]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5239, 0.4761]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5239, 0.4761]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4765, 0.5235]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5344, 0.4656]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5344, 0.4656]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4658, 0.5342]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4906, 0.5094]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4906, 0.5094]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5145, 0.4855]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5077, 0.4923]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5077, 0.4923]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4929, 0.5071]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.4990, 0.5010]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.4990, 0.5010]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5058, 0.4942]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "tensor([[0.5024, 0.4976]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5024, 0.4976]], grad_fn=<SoftmaxBackward0>) \n",
      " tensor([[0.5011, 0.4989]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------------------------------------\n",
      "CPU times: user 1min 30s, sys: 1.97 ms, total: 1min 30s\n",
      "Wall time: 1.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for HERO in HERO_TRANSFORM.values():\n",
    "    print(\n",
    "        torch.softmax(model(\n",
    "        (torch.as_tensor([[0, 0, 0, 0, HERO] + [0, 0, 0, 0, 0]]),\n",
    "         torch.as_tensor(5))  # ancient + rapier + immortal rank\n",
    "    ), dim=-1), '\\n',\n",
    "        torch.softmax(model(\n",
    "        (torch.as_tensor([[HERO, 0, 0, 0, 0] + [0, 0, 0, 0, 0]]),\n",
    "         torch.as_tensor(5))  # ancient + rapier + immortal rank\n",
    "    ), dim=-1), '\\n',\n",
    "        torch.softmax(model(\n",
    "        (torch.as_tensor([[0, 0, 0, 0, 0] + [HERO, 0, 0, 0, 0]]),\n",
    "         torch.as_tensor(5))  # ancient + rapier + immortal rank\n",
    "    ), dim=-1),\n",
    "    )\n",
    "    print('-' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47ca415b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(HERO_TRANSFORM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86d67c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/yarik/shad/picker/picker/model/training_model.py\u001b[0m(57)\u001b[0;36mplot_stuff\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     55 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     56 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccs_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 57 \u001b[0;31m            \u001b[0max2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'Test dataset number {idx}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     58 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     59 \u001b[0;31m    \u001b[0max2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accs on test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> idx\n",
      "0\n",
      "ipdb> accs[:, idx]\n",
      "*** TypeError: list indices must be integers or slices, not tuple\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21382dc0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "A = torch.cat((torch.ones(512, 5, 1), torch.zeros(512, 5, 1)), dim=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e96b3a05",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 10, 64])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((torch.rand(512, 10, 63), A), dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9e2ec1e8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "emb = torch.cat(embs).reshape(1, 10, -1)\n",
    "res = model(emb, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8f5db74b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4648]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cc9862da",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a = torch.rand(1, 10, 64)\n",
    "b = torch.rand(1, 1, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2ee0a0e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0823, 0.2277, 0.4079, 0.9386, 0.0742, 0.7202, 0.3607, 0.9005,\n",
       "          0.1608, 0.2063, 0.7980, 0.9442, 0.0333, 0.5649, 0.2936, 0.4545,\n",
       "          0.4625, 0.3905, 0.5795, 0.6908, 0.0839, 0.7522, 0.9392, 0.1067,\n",
       "          0.3177, 0.5344, 0.1385, 0.7366, 0.2210, 0.7947, 0.2109, 0.0716,\n",
       "          0.8087, 0.5818, 0.2675, 0.9628, 0.7965, 0.6796, 0.1220, 0.6453,\n",
       "          0.2468, 0.2309, 0.3061, 0.2880, 0.1987, 0.7911, 0.5555, 0.4565,\n",
       "          0.8999, 0.4815, 0.6246, 0.6285, 0.7902, 0.0816, 0.5806, 0.1977,\n",
       "          0.6592, 0.5274, 0.3737, 0.8188, 0.5043, 0.8749, 0.7966, 0.2408],\n",
       "         [0.9915, 0.3214, 0.3582, 0.4512, 0.1294, 0.6715, 0.8483, 0.3055,\n",
       "          0.6333, 0.0336, 0.1905, 0.7927, 0.0481, 0.4222, 0.6530, 0.4618,\n",
       "          0.4607, 0.9218, 0.1592, 0.9127, 0.1080, 0.6349, 0.9745, 0.8846,\n",
       "          0.1505, 0.5538, 0.9617, 0.9514, 0.5724, 0.8122, 0.7971, 0.8665,\n",
       "          0.4984, 0.1422, 0.6348, 0.0502, 0.9907, 0.4200, 0.7669, 0.3436,\n",
       "          0.3604, 0.8022, 0.5990, 0.7234, 0.7494, 0.0636, 0.9351, 0.0980,\n",
       "          0.0789, 0.2025, 0.9868, 0.8937, 0.0378, 0.8142, 0.0284, 0.4992,\n",
       "          0.1438, 0.5016, 0.7600, 0.4765, 0.3734, 0.1405, 0.7795, 0.0251],\n",
       "         [0.5293, 0.2018, 0.0844, 0.1540, 0.4002, 0.0924, 0.3899, 0.0934,\n",
       "          0.9307, 0.3287, 0.7514, 0.4496, 0.7419, 0.9695, 0.0035, 0.2762,\n",
       "          0.4364, 0.1528, 0.5141, 0.1903, 0.7141, 0.2052, 0.9015, 0.6373,\n",
       "          0.7493, 0.2597, 0.1370, 0.8378, 0.6878, 0.5573, 0.7830, 0.4222,\n",
       "          0.5416, 0.4588, 0.3011, 0.6952, 0.1071, 0.0123, 0.3640, 0.8499,\n",
       "          0.2097, 0.8281, 0.0107, 0.8978, 0.5376, 0.9874, 0.0979, 0.5948,\n",
       "          0.2382, 0.4197, 0.8722, 0.6351, 0.3813, 0.6243, 0.4186, 0.9045,\n",
       "          0.9252, 0.7115, 0.0873, 0.0066, 0.2528, 0.5448, 0.1491, 0.0279],\n",
       "         [0.6541, 0.7755, 0.9124, 0.2386, 0.9303, 0.6394, 0.6280, 0.2859,\n",
       "          0.3803, 0.4762, 0.2397, 0.4504, 0.5789, 0.6026, 0.5671, 0.6471,\n",
       "          0.6757, 0.9011, 0.4261, 0.6587, 0.5551, 0.4626, 0.3373, 0.5324,\n",
       "          0.4290, 0.6122, 0.8378, 0.4355, 0.3013, 0.8567, 0.5951, 0.6261,\n",
       "          0.3150, 0.6316, 0.7142, 0.6939, 0.1311, 0.6096, 0.4852, 0.6194,\n",
       "          0.3905, 0.9814, 0.8093, 0.0617, 0.5442, 0.3501, 0.7690, 0.0505,\n",
       "          0.7404, 0.6769, 0.5061, 0.9917, 0.2908, 0.6524, 0.3490, 0.6030,\n",
       "          0.0825, 0.6668, 0.6774, 0.7115, 0.0675, 0.0876, 0.2570, 0.6371],\n",
       "         [0.5840, 0.5832, 0.0052, 0.6166, 0.7060, 0.7878, 0.4759, 0.0299,\n",
       "          0.1702, 0.0015, 0.0524, 0.3143, 0.5947, 0.7588, 0.5520, 0.7063,\n",
       "          0.8212, 0.5072, 0.0109, 0.8222, 0.7773, 0.5531, 0.7468, 0.5336,\n",
       "          0.8232, 0.1228, 0.4631, 0.3645, 0.1787, 0.0723, 0.5087, 0.6076,\n",
       "          0.3451, 0.1867, 0.5293, 0.0898, 0.4184, 0.0594, 0.2631, 0.3308,\n",
       "          0.3140, 0.5641, 0.2176, 0.3231, 0.4512, 0.3237, 0.6240, 0.6286,\n",
       "          0.5233, 0.8640, 0.4884, 0.6676, 0.7101, 0.8141, 0.4087, 0.1198,\n",
       "          0.7689, 0.4025, 0.4457, 0.7073, 0.8809, 0.1204, 0.2977, 0.6291],\n",
       "         [0.7602, 0.1941, 0.1814, 0.8357, 0.2552, 0.1835, 0.1808, 0.7550,\n",
       "          0.8094, 0.4333, 0.2803, 0.9677, 0.8110, 0.2620, 0.1285, 0.8938,\n",
       "          0.0743, 0.1784, 0.2492, 0.6834, 0.4075, 0.4397, 0.4646, 0.8063,\n",
       "          0.2839, 0.3847, 0.2669, 0.3905, 0.5618, 0.5127, 0.4858, 0.3710,\n",
       "          0.7547, 0.1292, 0.6356, 0.9540, 0.7763, 0.6079, 0.0441, 0.5579,\n",
       "          0.8873, 0.4301, 0.5735, 0.3538, 0.4627, 0.7614, 0.0287, 0.9333,\n",
       "          0.9668, 0.2661, 0.9772, 0.7166, 0.2218, 0.8815, 0.9719, 0.4611,\n",
       "          0.4940, 0.3266, 0.7658, 0.0948, 0.3093, 0.3734, 0.6214, 0.0051],\n",
       "         [0.9832, 0.9382, 0.5820, 0.7930, 0.5799, 0.2555, 0.0709, 0.6375,\n",
       "          0.6401, 0.2857, 0.5358, 0.9106, 0.0392, 0.3800, 0.1549, 0.4879,\n",
       "          0.3350, 0.4970, 0.5349, 0.9027, 0.2923, 0.0475, 0.7000, 0.3203,\n",
       "          0.9962, 0.6034, 0.9463, 0.6152, 0.8277, 0.8009, 0.2342, 0.6138,\n",
       "          0.7191, 0.3468, 0.8755, 0.5255, 0.2566, 0.4009, 0.6918, 0.1554,\n",
       "          0.0107, 0.6356, 0.5246, 0.0458, 0.4779, 0.5567, 0.3952, 0.4024,\n",
       "          0.4245, 0.0828, 0.5241, 0.8014, 0.6057, 0.3194, 0.4891, 0.5413,\n",
       "          0.8584, 0.6335, 0.7113, 0.0176, 0.8114, 0.7749, 0.5689, 0.9057],\n",
       "         [0.7721, 0.7235, 0.2954, 0.0845, 0.5317, 0.1750, 0.1739, 0.9535,\n",
       "          0.6139, 0.5855, 0.7121, 0.7196, 0.8468, 0.1695, 0.2179, 0.2407,\n",
       "          0.4400, 0.9256, 0.3844, 0.5744, 0.3890, 0.6835, 0.6770, 0.3374,\n",
       "          0.4410, 0.3060, 0.3574, 0.7333, 0.4196, 0.4949, 0.5866, 0.4988,\n",
       "          0.1147, 0.1655, 0.0610, 0.0343, 0.0890, 0.3882, 0.0370, 0.2255,\n",
       "          0.9709, 0.2417, 0.9176, 0.1296, 0.1308, 0.5599, 0.8546, 0.0740,\n",
       "          0.3754, 0.1464, 0.4440, 0.5568, 0.1369, 0.2860, 0.0443, 0.6356,\n",
       "          0.9716, 0.3537, 0.3594, 0.1452, 0.3204, 0.0831, 0.4884, 0.9456],\n",
       "         [0.1998, 0.9068, 0.1662, 0.4164, 0.6412, 0.6337, 0.5139, 0.3187,\n",
       "          0.5103, 0.1513, 0.9069, 0.2180, 0.8722, 0.8175, 0.7816, 0.2586,\n",
       "          0.4479, 0.9598, 0.8401, 0.7611, 0.7954, 0.3649, 0.2509, 0.9704,\n",
       "          0.3266, 0.8086, 0.0696, 0.7843, 0.9367, 0.7041, 0.2391, 0.7051,\n",
       "          0.5108, 0.9436, 0.8010, 0.4399, 0.3961, 0.1482, 0.5670, 0.4278,\n",
       "          0.0119, 0.7118, 0.4939, 0.9925, 0.3332, 0.6947, 0.7053, 0.4467,\n",
       "          0.0016, 0.9353, 0.3694, 0.8494, 0.5796, 0.2367, 0.5490, 0.8449,\n",
       "          0.3541, 0.0894, 0.3926, 0.7148, 0.9888, 0.9692, 0.3940, 0.6058],\n",
       "         [0.9100, 0.2578, 0.5826, 0.3895, 0.4134, 0.4130, 0.7349, 0.0481,\n",
       "          0.7046, 0.7964, 0.4912, 0.0829, 0.5716, 0.5697, 0.8222, 0.8767,\n",
       "          0.7744, 0.0132, 0.2521, 0.6484, 0.3196, 0.9287, 0.9899, 0.6279,\n",
       "          0.3818, 0.0191, 0.4003, 0.6112, 0.9591, 0.9400, 0.3162, 0.9679,\n",
       "          0.0052, 0.6624, 0.1612, 0.8896, 0.4765, 0.5536, 0.7186, 0.6055,\n",
       "          0.9824, 0.3476, 0.1739, 0.3153, 0.2274, 0.1223, 0.0286, 0.9991,\n",
       "          0.3790, 0.5383, 0.3131, 0.9669, 0.7223, 0.2552, 0.2516, 0.8079,\n",
       "          0.9995, 0.2567, 0.2572, 0.3158, 0.2374, 0.9754, 0.5225, 0.9547],\n",
       "         [0.7513, 0.6373, 0.6079, 0.5457, 0.0253, 0.5822, 0.0145, 0.2817,\n",
       "          0.6781, 0.1516, 0.5298, 0.4035, 0.4687, 0.8971, 0.7024, 0.3031,\n",
       "          0.8951, 0.9295, 0.5192, 0.0371, 0.6743, 0.9490, 0.5785, 0.3177,\n",
       "          0.3501, 0.7659, 0.8354, 0.9838, 0.2668, 0.9544, 0.1281, 0.8120,\n",
       "          0.7903, 0.9839, 0.7097, 0.6038, 0.6920, 0.4135, 0.3742, 0.5870,\n",
       "          0.5387, 0.8026, 0.0936, 0.7274, 0.8193, 0.4428, 0.5523, 0.1838,\n",
       "          0.1538, 0.6625, 0.0537, 0.2950, 0.7551, 0.1240, 0.7675, 0.0023,\n",
       "          0.9708, 0.7863, 0.9456, 0.4821, 0.0328, 0.0438, 0.7103, 0.9658]]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((a, b), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04300dd2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841cc37d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
